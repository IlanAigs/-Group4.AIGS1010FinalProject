{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "e8f4f3a4",
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "# https://docs.opencv.org/4.x/dc/da5/tutorial_py_drawing_functions.html\n",
    "# Srouces\n",
    "# https://docs.opencv.org/3.4/d5/d6f/tutorial_feature_flann_matcher.html\n",
    "\n",
    "# AIGS1010 - Camputer vision, week 6 demo:\n",
    "    # https://loyalistcollege.instructure.com/courses/10557/pages/demo-resources?module_item_id=619758\n",
    "# https://www.geeksforgeeks.org/python-grayscaling-of-images-using-opencv/"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "275f61e7",
   "metadata": {},
   "source": [
    "The following part of the program is the first training part.\n",
    "It is designed to demonstrate the program implementation by showing the faces and the common keypoints.\n",
    "\n",
    "In this part, we make use of OpenCV (Open Source Computer Vision Library). This is an open-source library that includes several hundreds of computer vision algorithms.\n",
    "\n",
    "Step 1: In this part, we load the relevant modules from cv2.\n",
    "Step 2: In the training part, we will select a folder from our database and put the path to it under \"image_dir\",\n",
    "        and save them as a list of paths in the image_files variable.\n",
    "Step 3: At this stage, we use 2 for loops with the variables \"i\" and \"j\" to compare each face in our directory to every\n",
    "        other one, and find common keypoints.\n",
    "Step 3.1: In this step, we print the results to the console using \"matplotlib\", a Python library used for visualization.\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "fc25b7d7",
   "metadata": {},
   "outputs": [],
   "source": [
    "### training 1 ###\n",
    "# This part is for demostraiting the program by showing the faces and the commen key points\n",
    "\n",
    "\n",
    "import cv2\n",
    "import os\n",
    "from matplotlib import pyplot as plt\n",
    "\n",
    "# step 1:\n",
    "# Load the pre-trained face detector\n",
    "face_cascade = cv2.CascadeClassifier(cv2.data.haarcascades + 'haarcascade_frontalface_default.xml')\n",
    "\n",
    "# Initialize SIFT\n",
    "sift = cv2.SIFT_create()\n",
    "\n",
    "\n",
    "##################################################################################\n",
    "# step 2:\n",
    "# Path to the directory containing the images to be used for trauning and testing\n",
    "\n",
    "image_dir = r\"C:\\Users\\Ilan\\Desktop\\Face recognition\\gt_db\\gt_database 1\\gt_database 1\\gt_db\\Aidan\"\n",
    "\n",
    "\n",
    "# Get a list of all image filenames in the directory \n",
    "image_files = [file for file in os.listdir(image_dir) if file.endswith('.jpg')]\n",
    "\n",
    "#################################################################################\n",
    "#step 3:\n",
    "# https://www.geeksforgeeks.org/python-grayscaling-of-images-using-opencv/\n",
    "\n",
    "for i in range(len(image_files)): # all the images in the directory\n",
    "    for j in range(i+1, len(image_files)): # i and j will be used to compair the pictures to each other\n",
    "        # Read the images\n",
    "        img1 = cv2.imread(os.path.join(image_dir, image_files[i]), cv2.IMREAD_GRAYSCALE)\n",
    "        img2 = cv2.imread(os.path.join(image_dir, image_files[j]), cv2.IMREAD_GRAYSCALE)\n",
    "        \n",
    "        # Detect the faces in all of the pictures\n",
    "        faces1 = face_cascade.detectMultiScale(img1, scaleFactor=1.1, minNeighbors=5)\n",
    "        faces2 = face_cascade.detectMultiScale(img2, scaleFactor=1.1, minNeighbors=5)\n",
    "        \n",
    "        # Initialize lists to store common keypoints\n",
    "        common_kp1 = []\n",
    "        common_kp2 = []\n",
    "        \n",
    "        # https://www.geeksforgeeks.org/python-grayscaling-of-images-using-opencv/\n",
    "        # Extract keypoints and descriptors only within the detected faces\n",
    "        for (x, y, w, h) in faces1:\n",
    "            face_roi = img1[y:y+h, x:x+w]\n",
    "            kp1, des1 = sift.detectAndCompute(face_roi, None)\n",
    "            common_kp1.extend(kp1)\n",
    "            cv2.rectangle(img1, (x, y), (x+w, y+h), (255, 0, 0), 2)\n",
    "            for kp in common_kp1:\n",
    "                cv2.circle(img1, (int(kp.pt[0]) + x, int(kp.pt[1]) + y), 5, (0, 255, 0), -1)\n",
    "        \n",
    "        for (x, y, w, h) in faces2:\n",
    "            face_roi = img2[y:y+h, x:x+w]\n",
    "            kp2, des2 = sift.detectAndCompute(face_roi, None)\n",
    "            common_kp2.extend(kp2)\n",
    "            cv2.rectangle(img2, (x, y), (x+w, y+h), (255, 0, 0), 2)\n",
    "            for kp in common_kp2:\n",
    "                cv2.circle(img2, (int(kp.pt[0]) + x, int(kp.pt[1]) + y), 5, (0, 255, 0), -1)\n",
    "\n",
    "#################################################################################\n",
    "# step 3.1\n",
    "        # Display the images with faces and common keypoints\n",
    "        fig, axes = plt.subplots(1, 2, figsize=(10, 5))\n",
    "        axes[0].imshow(img1, cmap='gray')\n",
    "        axes[0].set_title(f'{image_files[i]} Common Keypoints')\n",
    "        axes[0].axis('off')\n",
    "\n",
    "        axes[1].imshow(img2, cmap='gray')\n",
    "        axes[1].set_title(f'{image_files[j]} Common Keypoints')\n",
    "        axes[1].axis('off')\n",
    "\n",
    "        plt.show()\n",
    "\n",
    "        # Compare the number of common keypoints in both faces\n",
    "        print(\"Number of common keypoints in\", image_files[i], \":\", len(common_kp1))\n",
    "        print(\"Number of common keypoints in\", image_files[j], \":\", len(common_kp2))\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "1911f0ea",
   "metadata": {},
   "source": [
    "This is the second training part.\n",
    "In this part, we go through the same process as in the first training part and then calculate a numerical value for the similarity of all faces from our training directory to all of the other faces in the directory. This gives us an average of all common keypoints in the training faces.\n",
    "Mathematically, it is:\n",
    "\n",
    "sum((x/y)+(y/x))/n\n",
    "\n",
    "where:\n",
    "x and y are represents the common keypoints for every pair of faces,\n",
    "n is the number of faces.\n",
    "\n",
    "The first lines of code are identical to parts 1 and 2 from the first training part.\n",
    "The last part of the code is a calculator that will extract the value we get for the real person.\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "06f12185",
   "metadata": {},
   "outputs": [],
   "source": [
    "### Training 2 ###\n",
    "# A calculator for the average ratio of common points between all training faces\n",
    "\n",
    "import cv2\n",
    "import os\n",
    "import numpy as np\n",
    "\n",
    "# Load the pre-trained face detector\n",
    "face_cascade = cv2.CascadeClassifier(cv2.data.haarcascades + 'haarcascade_frontalface_default.xml')\n",
    "\n",
    "# Initialize SIFT\n",
    "sift = cv2.SIFT_create()\n",
    "\n",
    "###########\n",
    "# Path to the directory containing the images\n",
    "image_dir = r\"C:\\Users\\Ilan\\Desktop\\Face recognition\\gt_db\\gt_database 1\\gt_database 1\\gt_db\\Aidan\"\n",
    "###########\n",
    "\n",
    "# Get a list of all image filenames in the directory\n",
    "image_files = [file for file in os.listdir(image_dir) if file.endswith('.jpg')]\n",
    "\n",
    "# Initialize a list to store the average number of common keypoints for each pair of images\n",
    "average_common_keypoints = []\n",
    "\n",
    "# Iterate over each pair of images\n",
    "for i in range(len(image_files)):\n",
    "    for j in range(i+1, len(image_files)):\n",
    "        # Read the images\n",
    "        img1 = cv2.imread(os.path.join(image_dir, image_files[i]), cv2.IMREAD_GRAYSCALE)\n",
    "        img2 = cv2.imread(os.path.join(image_dir, image_files[j]), cv2.IMREAD_GRAYSCALE)\n",
    "        \n",
    "        # Detect faces in the images\n",
    "        faces1 = face_cascade.detectMultiScale(img1, scaleFactor=1.1, minNeighbors=5)\n",
    "        faces2 = face_cascade.detectMultiScale(img2, scaleFactor=1.1, minNeighbors=5)\n",
    "        \n",
    "        # Initialize lists to store common keypoints\n",
    "        common_kp1 = []\n",
    "        common_kp2 = []\n",
    "        \n",
    "        # Extract keypoints and descriptors only within the detected faces\n",
    "        for (x, y, w, h) in faces1:\n",
    "            face_roi = img1[y:y+h, x:x+w]\n",
    "            kp1, des1 = sift.detectAndCompute(face_roi, None)\n",
    "            common_kp1.extend(kp1)\n",
    "        \n",
    "        for (x, y, w, h) in faces2:\n",
    "            face_roi = img2[y:y+h, x:x+w]\n",
    "            kp2, des2 = sift.detectAndCompute(face_roi, None)\n",
    "            common_kp2.extend(kp2)\n",
    "        \n",
    "        # Calculate the average number of common keypoints for this pair of images\n",
    "        average_keypoints = ((len(common_kp1) / len(common_kp2)) + (len(common_kp2) / len(common_kp1))) / 2\n",
    "        average_common_keypoints.append(average_keypoints)\n",
    "\n",
    "# Calculate the average value of each pair of pictures divided by the other\n",
    "average_value_real = sum(average_common_keypoints) / len(average_common_keypoints)\n",
    "print(\"Average value of common keypoints:\", average_value_real)\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "6b49932f",
   "metadata": {},
   "source": [
    "This is the testing part. This part simulates a scenario in which a person who wasn't tested wants to enter. \n",
    "To achieve this, we choose pictures of faces who do not belong to the person we had trained the program on.\n",
    "Like in the training phase, we compare all common keypoints between the 'real' person and the one wishing to access.\n",
    "The result of this computation is a larger value than in the training, and access is denied.\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "8f8311d8",
   "metadata": {},
   "outputs": [],
   "source": [
    "### Testing ###\n",
    "\n",
    "\n",
    "import cv2\n",
    "import os\n",
    "from matplotlib import pyplot as plt\n",
    "\n",
    "# Load the pre-trained face detector\n",
    "face_cascade = cv2.CascadeClassifier(cv2.data.haarcascades + 'haarcascade_frontalface_default.xml')\n",
    "\n",
    "# Initialize SIFT\n",
    "sift = cv2.SIFT_create()\n",
    "\n",
    "\n",
    "# Path to the directory containing the training faces\n",
    "image_dir = r\"C:\\Users\\Ilan\\Desktop\\Face recognition\\gt_db\\gt_database 1\\gt_database 1\\gt_db\\Aidan\"\n",
    "\n",
    "\n",
    "# Path to the directory containing the face of a person wishing to enter the system\n",
    "image_dir2 = r\"C:\\Users\\Ilan\\Desktop\\Face recognition\\gt_db\\gt_database 1\\gt_database 1\\gt_db\\Aidan\"\n",
    "\n",
    "\n",
    "\n",
    "# Get a list of all image filenames in the directories\n",
    "image_files = [file for file in os.listdir(image_dir) if file.endswith('.jpg')]\n",
    "image_files2 = [file for file in os.listdir(image_dir2) if file.endswith('.jpg')]\n",
    "\n",
    "# Initialize a list to store the average number of common keypoints for each pair of images\n",
    "average_common_keypoints = []\n",
    "\n",
    "# Iterate over each pair of images\n",
    "for i in range(len(image_files)):\n",
    "    for j in range(len(image_files2)):\n",
    "        # The real face from training\n",
    "        img1 = cv2.imread(os.path.join(image_dir, image_files[i]), cv2.IMREAD_GRAYSCALE)\n",
    "        # The person wishing to enter\n",
    "        img2 = cv2.imread(os.path.join(image_dir2, image_files2[j]), cv2.IMREAD_GRAYSCALE)\n",
    "        \n",
    "        # The real face from training\n",
    "        faces1 = face_cascade.detectMultiScale(img1, scaleFactor=1.1, minNeighbors=5)\n",
    "        # The person wishing to enter\n",
    "        faces2 = face_cascade.detectMultiScale(img2, scaleFactor=1.1, minNeighbors=5)\n",
    "        \n",
    "        # Lists for common keypoints\n",
    "        common_kp1 = []\n",
    "        common_kp2 = []\n",
    "        \n",
    "        # Extract keypoints and descriptors only within the detected faces for real person\n",
    "        for (x, y, w, h) in faces1:\n",
    "            face_roi = img1[y:y+h, x:x+w]\n",
    "            kp1, des1 = sift.detectAndCompute(face_roi, None)\n",
    "            common_kp1.extend(kp1)\n",
    "            cv2.rectangle(img1, (x, y), (x+w, y+h), (255, 0, 0), 2)\n",
    "            for kp in common_kp1:\n",
    "                cv2.circle(img1, (int(kp.pt[0]) + x, int(kp.pt[1]) + y), 5, (0, 255, 0), -1)\n",
    "                \n",
    "        # Extract keypoints and descriptors only within the detected faces for person wishing to enter\n",
    "        for (x, y, w, h) in faces2:\n",
    "            face_roi = img2[y:y+h, x:x+w]\n",
    "            kp2, des2 = sift.detectAndCompute(face_roi, None)\n",
    "            common_kp2.extend(kp2)\n",
    "            cv2.rectangle(img2, (x, y), (x+w, y+h), (255, 0, 0), 2)\n",
    "            for kp in common_kp2:\n",
    "                cv2.circle(img2, (int(kp.pt[0]) + x, int(kp.pt[1]) + y), 5, (0, 255, 0), -1)\n",
    "        \n",
    "        # Calculate the average number of common keypoints for both lists, the real person, and the one wishing to enter\n",
    "        if len(common_kp1) != 0 and len(common_kp2) != 0:\n",
    "            average_keypoints = ((len(common_kp1) / len(common_kp2)) + (len(common_kp2) / len(common_kp1))) / 2\n",
    "            average_common_keypoints.append(average_keypoints)\n",
    "            \n",
    "            \n",
    "            \n",
    "            # Display the images with detected faces and common keypoints\n",
    "            fig, axes = plt.subplots(1, 2, figsize=(10, 5))\n",
    "            axes[0].imshow(img1, cmap='gray')\n",
    "            axes[0].set_title(f'{image_files[i]} with Detected Faces and Common Keypoints')\n",
    "            axes[0].axis('off')\n",
    "            \n",
    "            axes[1].imshow(img2, cmap='gray')\n",
    "            axes[1].set_title(f'{image_files2[j]} with Detected Faces and Common Keypoints')\n",
    "            axes[1].axis('off')\n",
    "            \n",
    "            plt.show()\n",
    "            \n",
    "# Print the results of the comparison\n",
    "            print(f\"Comparison between {image_files[i]} and {image_files2[j]}:\")\n",
    "            print(\"Average value of common keypoints:\", average_keypoints)\n",
    "            print(\"-----------------------------------------\")\n",
    "\n",
    "# Check if there were any pairs with common keypoints\n",
    "if average_common_keypoints:\n",
    "    # Calculate the average value of each pair of pictures divided by the other\n",
    "    average_value_test = sum(average_common_keypoints) / len(average_common_keypoints)\n",
    "    print(\"Overall average value of common keypoints:\", average_value_test)\n",
    "else:\n",
    "    print(\"No common keypoints found.\")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "dac991b1",
   "metadata": {},
   "outputs": [],
   "source": [
    "print(average_value_real)\n",
    "print(average_value_test)\n",
    "\n",
    "if average_value_test > average_value_real:\n",
    "    print(\"Access denied\")\n",
    "else:\n",
    "    print(\"Access permitted\")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "8a3f0cd5",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "a7cd056a",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "3dcbdf0c",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.13"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
